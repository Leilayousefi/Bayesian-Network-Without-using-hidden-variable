# Bayesian-Network-Without-using-hidden-variable

1.	Without using hidden variable, “NoHidden_LilyAlgorithm28_1_2018_50percentPs_neg_INCREASE” with IC* structure from FirstIC* used in the 3rd step but without hidden “”
2.	First run "1_LilyAlgorithm28_1_2018_50percentPs_neg_INCREASE" to randomly resample the number of patients, which diagnosed positively to have retinopathy. The number of positive cases is increased by subtracting from the negative cases. Thus, a balanced dataset based on retinopathy is produced (with the same amount of positive and negative cases). Patients are shuffled in data set. We trained the model using “TrainHMM_AR_IC_LS_withoutK2” the structure used in here is our previous structure that obtained from the basic and unbalanced dataset. At this stage there is 13 different T2DM features plus one hidden variable and we learned the structure of new data set using IC* algorithm. Confusion matrix of this result is called : “beforeUsingIC_retino”.
3.	 Later we use this data set and the obtained data set to train and test next step of adding more hidden variables. Confusion matrix of this result is called : “1H_retino_firstStepofIC”.
Note: for pushing data in IC* algorithm data set obtained should be subtracted by one and prediction probabilities in the next stage should be rounded using a threshold of “0.1”. And Var (complication variable) in test set should be added in the following steps each time once.
4.	Run “Retino_script_30_1_18” to use the new data set and new structure found in the previous step. Train data in “New_retinoBalancedIC_TrainHMM_AR_IC_LS_withoutK2” shows one hidden variables which pointing to nodes (2,3,4,8,10,11). To test all data cell not just test cell to get probabilities of hidden to be added later and hence prediction probabilities of hidden variable was retrieved. Moreover, we use these probabilities to create another observed feature in another version of dataset “1H_firstStepofUsing IC_with13Obs.mat”.  
Then by running “FirstAddedHiddenDataSet_14Obs” we create a new version of dataset with added the first hidden as an observed variable. 
Note: Hidden probabilities needs to be rounded and added by one before pushing into train set and learning parameter procedure. And from now we have to be careful that variable (retinopathy is not the second node and adding one to var to be 3 for the next step.

By running “ICstarRun” for the datasetV1 “NewDataSet_Retino_firstH” and get the new IC* matrix for new Hidden structure and then add the new hidden variable pointing to the specific observed nodes that previously was not identified by comparing by previous IC* matrix.
5.	Run “”


6.	We continue the process until we get no hidden variable connections in IC* matrix or there is no improvement in the classification accuracy.
Then, I saved the balanced dataset and run IC* for it and I found all structure specially hidden pointing. I have just add one hidden to the new structure and pointed to those observed nodes that are in IC* matrix.
Then I add the prediction probability of this hidden to a second data set and save it as new data set. Then run IC* again and found the new hidden structure then assume the previous hidden as observed in the new data set and add new hidden to the previous structure (just change hidden node structure). Then I train the new data set and structure and get the new confusion matrix to see the results. And if there is any improvement then I will continue adding at least oone more.
The issue is for other complication like hypertension and liver IC* does not shows the hidden location in IC* matrix!
If you remember I told you instead of decreasing the amount of Negatives to be the same as negative cases, I would rather to increase the number of positives (randomly selected from the positive cases) to be the same as negatives, then I will get the better results and more patient cases.
If I do so then I will be getting a higher classification accuracy as you can see in the attached file.
Therefore, for the issue of not equality of IC* matrices for before and after applying this algorithm I have one solution if you agree!
In my opinion we could compare both IC* matrices for before and after applying this algorithm and then I found informative information matched in the both matrices. For example, "-2" in IC* matrix represent a marked (*) arrow from node a to node b in the underlying latent structure and at the same time shows there is no latent common cause for a and b; I mean there is no latent between those two nodes. then I can get the useful information from both IC* and then make sure the old and new data set do not find wrong location for latent variable and just find the links between observed variables from both matrices. Then I can look at "-1 or 2" in the matrices and try to search for matches in both matrices and each time choose one of them as the location of my latent variable?
For instance, I could say there is a marked link "-2 in IC*"between liver and smoking habit and there is no latent between these two nodes. And when there is "-1" in one of matrices and "2" in another then I can infer that there is a latent variable between these two nodes, as bidirected edge signifying a latent common cause in the underlying latent structure and no directed edge between two nodes.
Meanwhile, another option is I look at IC* of all three matrices balanced based on retinopathy, liver, hypertension and then compare with the old IC* matrix?

